{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Facial Detection CNN","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPPU2qVIsLNrUP5sBhyiVmy"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"15iQDJbXQ8tq","colab_type":"text"},"source":["# **1. Importing Necessary Files and Libraries**"]},{"cell_type":"code","metadata":{"id":"jzV6rS0gOwCr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600537311236,"user_tz":180,"elapsed":1155,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}},"outputId":"0b90fcfa-b175-47d4-99e0-e0340b30672c"},"source":["# mounting drive to colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KYNrb2eEP73R","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600537313568,"user_tz":180,"elapsed":3475,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}}},"source":["# importing python file containing CNN architecture\n","!cp \"drive/My Drive/Facial Classification - Gender/CNN_Models/smallervggnet.py\" .\n","!cp \"drive/My Drive/Facial Classification - Gender/CNN_Models/cnn_first.py\" .\n","from smallervggnet import SmallerVGGNet\n","from cnn_first import Simple_CNN"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"s9im11DARZg-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600537314105,"user_tz":180,"elapsed":4004,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}}},"source":["# importing the necessary packages\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import SGD\n","from keras.models import load_model\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import pickle\n","import cv2\n","import os\n","\n","# set the matplotlib backend so figures can be saved in the background\n","import matplotlib\n","matplotlib.use('Agg')\n","\n","# defining paths for saving results and image sizes\n","SAVE_PATH_VGG = 'drive/My Drive/Facial Classification - Gender/VGG_results'\n","SAVE_PATH_CNN = 'drive/My Drive/Facial Classification - Gender/SimpleCNN_results'\n","IMG_WIDTH = 64\n","IMG_HEIGHT = 64"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IaEFC_BwSeQ5","colab_type":"text"},"source":["# **2. Loading Images**"]},{"cell_type":"code","metadata":{"id":"CjZiPGeuTIzJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600537344293,"user_tz":180,"elapsed":34183,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}},"outputId":"773323f5-046c-4203-f88e-a8e05ca6cedd"},"source":["# initialize the data and labels\n","print('[INFORMATION] Loading images...')\n","data = []\n","labels = []\n","\n","# grab the images and randomly shuffle them\n","DATASET_PATH = 'drive/My Drive/Facial Classification - Gender/dataset_genre'\n","imagePaths = sorted(list(paths.list_images(DATASET_PATH)))\n","random.seed(42)\n","random.shuffle(imagePaths)\n","\n","# loop over the input images\n","for imagePath in imagePaths:\n","  # load the image, resize it to 64 x 64 pixels (the required input spatial dimensions of SmallerVGGNet),\n","  # and store it in the data list\n","  image = cv2.imread(imagePath)\n","  image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n","  data.append(image)\n","\n","  # extract the class label from the image path and update the labels list\n","  label = imagePath.split(os.path.sep)[-2]\n","  labels.append(label)\n","\n","print('[INFORMATION] Images Loaded and Labels Extracted sucessfully!')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[INFORMATION] Loading images...\n","[INFORMATION] Images Loaded and Labels Extracted sucessfully!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MJCcyrggzcn9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600537344294,"user_tz":180,"elapsed":34173,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}},"outputId":"b4c42cde-8d54-481d-c631-43c2f893d7b9"},"source":["print('Dataset size: {} images of 2 labels'.format(len(data)))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Dataset size: 6770 images of 2 labels\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R9kvoaR6fXIp","colab_type":"text"},"source":["# **3. Data Preprocessing and Data Augmentation**"]},{"cell_type":"code","metadata":{"id":"xExUeN0LffRY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600537344756,"user_tz":180,"elapsed":34620,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}}},"source":["# scale the raw pixel intensities to the range [0, 1]\n","data = np.array(data, dtype = 'float')/255.0\n","labels = np.array(labels)\n","\n","# partition the data into training and testing splits using 75 % of the data for training and the remaining 25 % for testing\n","(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size = 0.25, random_state=42)\n","\n","# convert the labels from strings to integers\n","lb = LabelBinarizer()\n","trainY = lb.fit_transform(trainY)\n","testY = lb.fit_transform(testY)\n","\n","# now, convert the labels from integers to vectors\n","trainY = to_categorical(trainY, num_classes=2, dtype='float32')\n","testY = to_categorical(testY, num_classes=2, dtype='float32')\n","\n","# construct image generator for data augmentation\n","aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n","                         height_shift_range = 0.1, shear_range = 0.2,\n","                         zoom_range = 0.2, horizontal_flip = True,\n","                         fill_mode = 'nearest')"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SGAVnj7Lm9qN","colab_type":"text"},"source":["# **4. First Model Initializing - VGG Architecture**"]},{"cell_type":"code","metadata":{"id":"DyduqyWenIvy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600537345169,"user_tz":180,"elapsed":35024,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}},"outputId":"3f79e5d1-2ac7-47bc-b515-3a6397f2f7ce"},"source":["# initialize our VGG-lie Convolutional Neural Network\n","model = SmallerVGGNet.build(width=IMG_WIDTH, height=IMG_HEIGHT, depth=3, classes=len(lb.classes_))\n","\n","# initialize our initial learning rage, # of epochs to train for and batch size\n","INIT_LR = 0.01\n","EPOCHS = 75\n","BATCH_SIZE = 32\n","\n","# initialize the model and optimizer\n","print('[INFORMATION] Loading Neural Network Model...')\n","opt = SGD(lr = INIT_LR, decay = INIT_LR/EPOCHS)\n","model.compile(loss='categorical_crossentropy', optimizer = opt, metrics=['accuracy'])\n","print('[INFORMATION] Neural Network Model successfully loaded!\\n')\n","model.summary()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[INFORMATION] Loading Neural Network Model...\n","[INFORMATION] Neural Network Model successfully loaded!\n","\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 64, 64, 32)        896       \n","_________________________________________________________________\n","activation (Activation)      (None, 64, 64, 32)        0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 64, 64, 32)        128       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 21, 21, 32)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 21, 21, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 21, 21, 64)        18496     \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 21, 21, 64)        0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 21, 21, 64)        256       \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 21, 21, 64)        36928     \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 21, 21, 64)        0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 21, 21, 64)        256       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 10, 10, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 10, 10, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 10, 10, 128)       73856     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 10, 10, 128)       0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 10, 10, 128)       512       \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 10, 10, 128)       147584    \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 10, 10, 128)       0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 10, 10, 128)       512       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 3200)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1024)              3277824   \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 1024)              0         \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2)                 2050      \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 2)                 0         \n","=================================================================\n","Total params: 3,563,394\n","Trainable params: 3,560,514\n","Non-trainable params: 2,880\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EwWXTE05pktY","colab_type":"text"},"source":["# **5. First Model Training**"]},{"cell_type":"code","metadata":{"id":"9YiMmZ7npvWr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600542950985,"user_tz":180,"elapsed":5640830,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}},"outputId":"dcef5f45-29fc-45e7-f999-007f00247b3e"},"source":["# train the network\n","print('[INFORMATION] Starting First Model Training...')\n","H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n","                        validation_data = (testX, testY),\n","                        steps_per_epoch = len(trainX)//BATCH_SIZE,\n","                        epochs = EPOCHS)\n","print('[INFORMATION] First CNN Model sucessfully trained')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[INFORMATION] Starting First Model Training...\n","WARNING:tensorflow:From <ipython-input-8-ef6281bd2369>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.fit, which supports generators.\n","Epoch 1/75\n","158/158 [==============================] - 74s 469ms/step - loss: 0.9361 - accuracy: 0.6202 - val_loss: 0.9367 - val_accuracy: 0.4985\n","Epoch 2/75\n","158/158 [==============================] - 74s 467ms/step - loss: 0.7180 - accuracy: 0.6714 - val_loss: 0.8888 - val_accuracy: 0.5304\n","Epoch 3/75\n","158/158 [==============================] - 74s 467ms/step - loss: 0.6211 - accuracy: 0.7064 - val_loss: 0.6471 - val_accuracy: 0.6444\n","Epoch 4/75\n","158/158 [==============================] - 78s 496ms/step - loss: 0.5904 - accuracy: 0.7138 - val_loss: 0.6388 - val_accuracy: 0.6592\n","Epoch 5/75\n","158/158 [==============================] - 74s 467ms/step - loss: 0.5782 - accuracy: 0.7245 - val_loss: 0.5274 - val_accuracy: 0.7265\n","Epoch 6/75\n","158/158 [==============================] - 74s 467ms/step - loss: 0.5677 - accuracy: 0.7233 - val_loss: 0.5246 - val_accuracy: 0.7354\n","Epoch 7/75\n","158/158 [==============================] - 74s 468ms/step - loss: 0.5450 - accuracy: 0.7356 - val_loss: 0.4856 - val_accuracy: 0.7679\n","Epoch 8/75\n","158/158 [==============================] - 74s 467ms/step - loss: 0.5337 - accuracy: 0.7487 - val_loss: 0.4724 - val_accuracy: 0.7667\n","Epoch 9/75\n","158/158 [==============================] - 74s 468ms/step - loss: 0.5187 - accuracy: 0.7562 - val_loss: 0.5239 - val_accuracy: 0.7348\n","Epoch 10/75\n","158/158 [==============================] - 74s 466ms/step - loss: 0.5295 - accuracy: 0.7493 - val_loss: 0.4998 - val_accuracy: 0.7501\n","Epoch 11/75\n","158/158 [==============================] - 74s 467ms/step - loss: 0.5071 - accuracy: 0.7584 - val_loss: 0.5306 - val_accuracy: 0.7425\n","Epoch 12/75\n","158/158 [==============================] - 77s 489ms/step - loss: 0.5099 - accuracy: 0.7554 - val_loss: 0.4662 - val_accuracy: 0.7761\n","Epoch 13/75\n","158/158 [==============================] - 74s 469ms/step - loss: 0.4941 - accuracy: 0.7649 - val_loss: 0.4218 - val_accuracy: 0.8139\n","Epoch 14/75\n","158/158 [==============================] - 74s 468ms/step - loss: 0.5028 - accuracy: 0.7651 - val_loss: 0.4799 - val_accuracy: 0.7614\n","Epoch 15/75\n","158/158 [==============================] - 75s 472ms/step - loss: 0.4922 - accuracy: 0.7681 - val_loss: 0.4465 - val_accuracy: 0.7915\n","Epoch 16/75\n","158/158 [==============================] - 74s 470ms/step - loss: 0.4727 - accuracy: 0.7818 - val_loss: 0.4127 - val_accuracy: 0.8104\n","Epoch 17/75\n","158/158 [==============================] - 74s 469ms/step - loss: 0.4716 - accuracy: 0.7859 - val_loss: 0.6296 - val_accuracy: 0.6834\n","Epoch 18/75\n","158/158 [==============================] - 74s 469ms/step - loss: 0.4718 - accuracy: 0.7778 - val_loss: 0.4287 - val_accuracy: 0.7986\n","Epoch 19/75\n","158/158 [==============================] - 74s 471ms/step - loss: 0.4649 - accuracy: 0.7808 - val_loss: 0.4001 - val_accuracy: 0.8122\n","Epoch 20/75\n","158/158 [==============================] - 78s 492ms/step - loss: 0.4528 - accuracy: 0.7925 - val_loss: 0.6110 - val_accuracy: 0.7301\n","Epoch 21/75\n","158/158 [==============================] - 74s 470ms/step - loss: 0.4482 - accuracy: 0.7980 - val_loss: 0.4044 - val_accuracy: 0.8133\n","Epoch 22/75\n","158/158 [==============================] - 74s 466ms/step - loss: 0.4363 - accuracy: 0.8018 - val_loss: 0.3835 - val_accuracy: 0.8269\n","Epoch 23/75\n","158/158 [==============================] - 74s 468ms/step - loss: 0.4543 - accuracy: 0.7905 - val_loss: 0.5646 - val_accuracy: 0.7283\n","Epoch 24/75\n","158/158 [==============================] - 74s 468ms/step - loss: 0.4469 - accuracy: 0.8010 - val_loss: 0.3698 - val_accuracy: 0.8411\n","Epoch 25/75\n","158/158 [==============================] - 74s 465ms/step - loss: 0.4240 - accuracy: 0.8097 - val_loss: 0.4581 - val_accuracy: 0.7891\n","Epoch 26/75\n","158/158 [==============================] - 74s 466ms/step - loss: 0.4297 - accuracy: 0.8006 - val_loss: 0.3744 - val_accuracy: 0.8358\n","Epoch 27/75\n","158/158 [==============================] - 74s 467ms/step - loss: 0.4298 - accuracy: 0.8048 - val_loss: 0.3576 - val_accuracy: 0.8470\n","Epoch 28/75\n","158/158 [==============================] - 78s 491ms/step - loss: 0.4148 - accuracy: 0.8095 - val_loss: 0.3434 - val_accuracy: 0.8458\n","Epoch 29/75\n","158/158 [==============================] - 73s 465ms/step - loss: 0.4084 - accuracy: 0.8155 - val_loss: 0.3192 - val_accuracy: 0.8653\n","Epoch 30/75\n","158/158 [==============================] - 74s 466ms/step - loss: 0.4195 - accuracy: 0.8105 - val_loss: 0.3973 - val_accuracy: 0.8086\n","Epoch 31/75\n","158/158 [==============================] - 74s 466ms/step - loss: 0.4148 - accuracy: 0.8105 - val_loss: 0.6780 - val_accuracy: 0.7047\n","Epoch 32/75\n","158/158 [==============================] - 74s 470ms/step - loss: 0.4022 - accuracy: 0.8222 - val_loss: 0.3896 - val_accuracy: 0.8275\n","Epoch 33/75\n","158/158 [==============================] - 74s 467ms/step - loss: 0.4059 - accuracy: 0.8168 - val_loss: 0.3536 - val_accuracy: 0.8393\n","Epoch 34/75\n","158/158 [==============================] - 74s 468ms/step - loss: 0.4040 - accuracy: 0.8155 - val_loss: 0.4783 - val_accuracy: 0.7832\n","Epoch 35/75\n","158/158 [==============================] - 74s 466ms/step - loss: 0.3956 - accuracy: 0.8202 - val_loss: 0.6148 - val_accuracy: 0.7584\n","Epoch 36/75\n","158/158 [==============================] - 74s 467ms/step - loss: 0.4031 - accuracy: 0.8161 - val_loss: 0.3379 - val_accuracy: 0.8529\n","Epoch 37/75\n","158/158 [==============================] - 77s 487ms/step - loss: 0.3917 - accuracy: 0.8256 - val_loss: 0.3257 - val_accuracy: 0.8571\n","Epoch 38/75\n","158/158 [==============================] - 73s 460ms/step - loss: 0.4041 - accuracy: 0.8202 - val_loss: 0.4489 - val_accuracy: 0.7897\n","Epoch 39/75\n","158/158 [==============================] - 73s 459ms/step - loss: 0.3871 - accuracy: 0.8311 - val_loss: 0.2940 - val_accuracy: 0.8783\n","Epoch 40/75\n","158/158 [==============================] - 73s 461ms/step - loss: 0.3819 - accuracy: 0.8335 - val_loss: 0.2976 - val_accuracy: 0.8718\n","Epoch 41/75\n","158/158 [==============================] - 73s 462ms/step - loss: 0.3786 - accuracy: 0.8365 - val_loss: 0.3841 - val_accuracy: 0.8364\n","Epoch 42/75\n","158/158 [==============================] - 73s 459ms/step - loss: 0.3883 - accuracy: 0.8260 - val_loss: 0.3014 - val_accuracy: 0.8671\n","Epoch 43/75\n","158/158 [==============================] - 73s 461ms/step - loss: 0.3814 - accuracy: 0.8295 - val_loss: 0.5745 - val_accuracy: 0.7673\n","Epoch 44/75\n","158/158 [==============================] - 74s 466ms/step - loss: 0.3894 - accuracy: 0.8317 - val_loss: 0.4126 - val_accuracy: 0.8187\n","Epoch 45/75\n","158/158 [==============================] - 78s 493ms/step - loss: 0.3760 - accuracy: 0.8256 - val_loss: 0.3882 - val_accuracy: 0.8293\n","Epoch 46/75\n","158/158 [==============================] - 73s 463ms/step - loss: 0.3761 - accuracy: 0.8351 - val_loss: 0.4545 - val_accuracy: 0.8039\n","Epoch 47/75\n","158/158 [==============================] - 73s 463ms/step - loss: 0.3729 - accuracy: 0.8341 - val_loss: 0.3487 - val_accuracy: 0.8529\n","Epoch 48/75\n","158/158 [==============================] - 73s 462ms/step - loss: 0.3741 - accuracy: 0.8309 - val_loss: 0.3801 - val_accuracy: 0.8317\n","Epoch 49/75\n","158/158 [==============================] - 73s 465ms/step - loss: 0.3757 - accuracy: 0.8375 - val_loss: 0.3826 - val_accuracy: 0.8364\n","Epoch 50/75\n","158/158 [==============================] - 73s 463ms/step - loss: 0.3677 - accuracy: 0.8383 - val_loss: 0.4470 - val_accuracy: 0.8198\n","Epoch 51/75\n","158/158 [==============================] - 73s 464ms/step - loss: 0.3593 - accuracy: 0.8460 - val_loss: 0.2788 - val_accuracy: 0.8777\n","Epoch 52/75\n","158/158 [==============================] - 73s 463ms/step - loss: 0.3573 - accuracy: 0.8402 - val_loss: 0.3268 - val_accuracy: 0.8547\n","Epoch 53/75\n","158/158 [==============================] - 78s 492ms/step - loss: 0.3576 - accuracy: 0.8381 - val_loss: 0.2889 - val_accuracy: 0.8760\n","Epoch 54/75\n","158/158 [==============================] - 74s 466ms/step - loss: 0.3588 - accuracy: 0.8383 - val_loss: 0.2988 - val_accuracy: 0.8730\n","Epoch 55/75\n","158/158 [==============================] - 74s 467ms/step - loss: 0.3548 - accuracy: 0.8434 - val_loss: 0.3509 - val_accuracy: 0.8535\n","Epoch 56/75\n","158/158 [==============================] - 74s 469ms/step - loss: 0.3575 - accuracy: 0.8442 - val_loss: 0.3015 - val_accuracy: 0.8724\n","Epoch 57/75\n","158/158 [==============================] - 74s 469ms/step - loss: 0.3499 - accuracy: 0.8492 - val_loss: 0.2879 - val_accuracy: 0.8825\n","Epoch 58/75\n","158/158 [==============================] - 74s 470ms/step - loss: 0.3395 - accuracy: 0.8523 - val_loss: 0.2708 - val_accuracy: 0.8860\n","Epoch 59/75\n","158/158 [==============================] - 74s 468ms/step - loss: 0.3400 - accuracy: 0.8511 - val_loss: 0.2687 - val_accuracy: 0.8836\n","Epoch 60/75\n","158/158 [==============================] - 74s 469ms/step - loss: 0.3430 - accuracy: 0.8478 - val_loss: 0.2744 - val_accuracy: 0.8813\n","Epoch 61/75\n","158/158 [==============================] - 78s 493ms/step - loss: 0.3561 - accuracy: 0.8416 - val_loss: 0.3311 - val_accuracy: 0.8553\n","Epoch 62/75\n","158/158 [==============================] - 74s 471ms/step - loss: 0.3333 - accuracy: 0.8531 - val_loss: 0.2633 - val_accuracy: 0.8890\n","Epoch 63/75\n","158/158 [==============================] - 74s 468ms/step - loss: 0.3391 - accuracy: 0.8517 - val_loss: 0.2695 - val_accuracy: 0.8801\n","Epoch 64/75\n","158/158 [==============================] - 74s 467ms/step - loss: 0.3313 - accuracy: 0.8492 - val_loss: 0.3569 - val_accuracy: 0.8494\n","Epoch 65/75\n","158/158 [==============================] - 74s 469ms/step - loss: 0.3455 - accuracy: 0.8557 - val_loss: 0.2562 - val_accuracy: 0.8966\n","Epoch 66/75\n","158/158 [==============================] - 74s 471ms/step - loss: 0.3354 - accuracy: 0.8496 - val_loss: 0.3067 - val_accuracy: 0.8748\n","Epoch 67/75\n","158/158 [==============================] - 74s 468ms/step - loss: 0.3337 - accuracy: 0.8561 - val_loss: 0.2652 - val_accuracy: 0.8925\n","Epoch 68/75\n","158/158 [==============================] - 74s 468ms/step - loss: 0.3245 - accuracy: 0.8571 - val_loss: 0.2422 - val_accuracy: 0.8972\n","Epoch 69/75\n","158/158 [==============================] - 77s 489ms/step - loss: 0.3299 - accuracy: 0.8527 - val_loss: 0.2858 - val_accuracy: 0.8789\n","Epoch 70/75\n","158/158 [==============================] - 74s 471ms/step - loss: 0.3305 - accuracy: 0.8549 - val_loss: 0.2422 - val_accuracy: 0.9019\n","Epoch 71/75\n","158/158 [==============================] - 74s 469ms/step - loss: 0.3233 - accuracy: 0.8616 - val_loss: 0.2440 - val_accuracy: 0.8966\n","Epoch 72/75\n","158/158 [==============================] - 74s 468ms/step - loss: 0.3333 - accuracy: 0.8577 - val_loss: 0.2734 - val_accuracy: 0.8895\n","Epoch 73/75\n","158/158 [==============================] - 74s 469ms/step - loss: 0.3354 - accuracy: 0.8488 - val_loss: 0.3484 - val_accuracy: 0.8636\n","Epoch 74/75\n","158/158 [==============================] - 74s 468ms/step - loss: 0.3132 - accuracy: 0.8612 - val_loss: 0.2486 - val_accuracy: 0.8966\n","Epoch 75/75\n","158/158 [==============================] - 74s 468ms/step - loss: 0.3271 - accuracy: 0.8559 - val_loss: 0.2660 - val_accuracy: 0.8925\n","[INFORMATION] First CNN Model sucessfully trained\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m-bw6udIAzo-","colab_type":"text"},"source":["# **6. First Model Evaluation**"]},{"cell_type":"code","metadata":{"id":"R6j8I0UOA9ri","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":343},"executionInfo":{"status":"ok","timestamp":1600544014327,"user_tz":180,"elapsed":10627,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}},"outputId":"d7263b81-3e24-4d18-81dc-506a94ca1255"},"source":["# evaluate the network\n","print('[INFORMATION] Starting Neural Network Evaluation...')\n","predictions = model.predict(testX, batch_size = 32)\n","print(classification_report(testY.argmax(axis=1),\n","                            predictions.argmax(axis = 1),\n","                            target_names = lb.classes_))\n","\n","# plot the training loss and accuracy curves\n","N = np.arange(0, EPOCHS)\n","plt.style.use('ggplot')\n","plt.figure(figsize=(20,20))\n","plt.plot(N, H.history['loss'], label = 'train_loss')\n","plt.plot(N, H.history['val_loss'], label = 'val_loss')\n","plt.plot(N, H.history['accuracy'], label = 'train_acc')\n","plt.plot(N, H.history['val_accuracy'], label = 'val_acc')\n","plt.title('Training Loss and Accuracy (SmallerVGGNet)')\n","plt.xlabel('Epoch #')\n","plt.ylabel('Loss / Accuracy')\n","plt.legend()\n","plt.show()\n","plt.savefig(SAVE_PATH_VGG + '/learning_curves.png')\n","\n","# save the model and label binarizer to disk\n","print('[INFORMATION] Serializing Network and Label Binarizer...')\n","model.save(SAVE_PATH_VGG)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[INFORMATION] Starting Neural Network Evaluation...\n","              precision    recall  f1-score   support\n","\n","         Man       0.86      0.94      0.90       849\n","       Woman       0.93      0.84      0.89       844\n","\n","    accuracy                           0.89      1693\n","   macro avg       0.90      0.89      0.89      1693\n","weighted avg       0.90      0.89      0.89      1693\n","\n","[INFORMATION] Serializing Network and Label Binarizer...\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","INFO:tensorflow:Assets written to: drive/My Drive/Facial Classification - Gender/VGG_results/assets\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vl1jAJhhhDl9","colab_type":"text"},"source":["# **7. Second Model Initializing - Double Convolution Architecture**"]},{"cell_type":"code","metadata":{"id":"S2O06Y8GhK4N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":510},"executionInfo":{"status":"ok","timestamp":1600544024258,"user_tz":180,"elapsed":954,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}},"outputId":"adcabfea-d7a5-47f4-d90f-72a063412747"},"source":["# initialize our Simple Convolutional Neural Network\n","model = Simple_CNN.build(width=IMG_WIDTH, height=IMG_HEIGHT, depth=3, classes=len(lb.classes_))\n","\n","# initialize our initial learning rage, # of epochs to train for and batch size\n","EPOCHS = 150\n","BATCH_SIZE = 32\n","\n","# initialize the model and optimizer\n","print('[INFORMATION] Loading Neural Network Model...')\n","model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n","print('[INFORMATION] Neural Network Model successfully loaded!\\n')\n","model.summary()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[INFORMATION] Loading Neural Network Model...\n","[INFORMATION] Neural Network Model successfully loaded!\n","\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_5 (Conv2D)            (None, 62, 62, 32)        896       \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 31, 31, 32)        0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 29, 29, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 6272)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1024)              6423552   \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 1024)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 2)                 2050      \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 2)                 0         \n","=================================================================\n","Total params: 6,435,746\n","Trainable params: 6,435,746\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ITs1yF5M0GsW","colab_type":"text"},"source":["# **8. Second Model Training**"]},{"cell_type":"code","metadata":{"id":"ztcLWxoe1O9a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600549456806,"user_tz":180,"elapsed":5428643,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}},"outputId":"de88fdf6-e5b9-484d-9b34-c93d3b5d9686"},"source":["# train the network\n","print('[INFORMATION] Starting Second Model Training...')\n","H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n","                        validation_data = (testX, testY),\n","                        steps_per_epoch = len(trainX)//BATCH_SIZE,\n","                        epochs = EPOCHS)\n","print('[INFORMATION] Second CNN Model sucessfully trained')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[INFORMATION] Starting Second Model Training...\n","Epoch 1/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.6662 - accuracy: 0.6246 - val_loss: 0.5185 - val_accuracy: 0.7318\n","Epoch 2/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.5338 - accuracy: 0.7386 - val_loss: 0.4757 - val_accuracy: 0.7809\n","Epoch 3/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.5064 - accuracy: 0.7554 - val_loss: 0.4096 - val_accuracy: 0.8116\n","Epoch 4/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.4875 - accuracy: 0.7679 - val_loss: 0.4122 - val_accuracy: 0.8133\n","Epoch 5/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.4727 - accuracy: 0.7754 - val_loss: 0.3998 - val_accuracy: 0.8240\n","Epoch 6/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.4488 - accuracy: 0.7939 - val_loss: 0.3779 - val_accuracy: 0.8334\n","Epoch 7/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.4392 - accuracy: 0.7990 - val_loss: 0.3566 - val_accuracy: 0.8441\n","Epoch 8/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.4161 - accuracy: 0.8077 - val_loss: 0.3954 - val_accuracy: 0.8222\n","Epoch 9/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.4055 - accuracy: 0.8190 - val_loss: 0.3679 - val_accuracy: 0.8387\n","Epoch 10/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.4066 - accuracy: 0.8242 - val_loss: 0.3230 - val_accuracy: 0.8600\n","Epoch 11/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.3963 - accuracy: 0.8220 - val_loss: 0.3147 - val_accuracy: 0.8630\n","Epoch 12/150\n","158/158 [==============================] - 36s 229ms/step - loss: 0.3725 - accuracy: 0.8279 - val_loss: 0.3034 - val_accuracy: 0.8706\n","Epoch 13/150\n","158/158 [==============================] - 36s 228ms/step - loss: 0.3791 - accuracy: 0.8295 - val_loss: 0.3533 - val_accuracy: 0.8488\n","Epoch 14/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.3726 - accuracy: 0.8387 - val_loss: 0.3456 - val_accuracy: 0.8517\n","Epoch 15/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.3603 - accuracy: 0.8408 - val_loss: 0.3407 - val_accuracy: 0.8600\n","Epoch 16/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.3520 - accuracy: 0.8472 - val_loss: 0.2814 - val_accuracy: 0.8795\n","Epoch 17/150\n","158/158 [==============================] - 40s 254ms/step - loss: 0.3391 - accuracy: 0.8537 - val_loss: 0.2843 - val_accuracy: 0.8736\n","Epoch 18/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.3320 - accuracy: 0.8603 - val_loss: 0.2663 - val_accuracy: 0.8901\n","Epoch 19/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.3416 - accuracy: 0.8513 - val_loss: 0.3291 - val_accuracy: 0.8600\n","Epoch 20/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.3233 - accuracy: 0.8634 - val_loss: 0.2724 - val_accuracy: 0.8890\n","Epoch 21/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.3266 - accuracy: 0.8605 - val_loss: 0.2592 - val_accuracy: 0.8978\n","Epoch 22/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.3227 - accuracy: 0.8599 - val_loss: 0.2742 - val_accuracy: 0.8854\n","Epoch 23/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.3167 - accuracy: 0.8620 - val_loss: 0.2571 - val_accuracy: 0.8960\n","Epoch 24/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.3033 - accuracy: 0.8684 - val_loss: 0.2682 - val_accuracy: 0.8931\n","Epoch 25/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.3015 - accuracy: 0.8686 - val_loss: 0.2633 - val_accuracy: 0.8913\n","Epoch 26/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.2984 - accuracy: 0.8731 - val_loss: 0.2422 - val_accuracy: 0.8949\n","Epoch 27/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.2903 - accuracy: 0.8714 - val_loss: 0.3023 - val_accuracy: 0.8819\n","Epoch 28/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2981 - accuracy: 0.8723 - val_loss: 0.2397 - val_accuracy: 0.8990\n","Epoch 29/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2863 - accuracy: 0.8783 - val_loss: 0.2433 - val_accuracy: 0.9025\n","Epoch 30/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2877 - accuracy: 0.8791 - val_loss: 0.2460 - val_accuracy: 0.8996\n","Epoch 31/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.2747 - accuracy: 0.8823 - val_loss: 0.2416 - val_accuracy: 0.9037\n","Epoch 32/150\n","158/158 [==============================] - 36s 228ms/step - loss: 0.2658 - accuracy: 0.8834 - val_loss: 0.2709 - val_accuracy: 0.8937\n","Epoch 33/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2695 - accuracy: 0.8870 - val_loss: 0.2435 - val_accuracy: 0.9002\n","Epoch 34/150\n","158/158 [==============================] - 42s 267ms/step - loss: 0.2613 - accuracy: 0.8874 - val_loss: 0.2192 - val_accuracy: 0.9061\n","Epoch 35/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.2658 - accuracy: 0.8932 - val_loss: 0.2442 - val_accuracy: 0.9037\n","Epoch 36/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2647 - accuracy: 0.8894 - val_loss: 0.2298 - val_accuracy: 0.9002\n","Epoch 37/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.2633 - accuracy: 0.8926 - val_loss: 0.2287 - val_accuracy: 0.9043\n","Epoch 38/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2708 - accuracy: 0.8894 - val_loss: 0.2339 - val_accuracy: 0.8984\n","Epoch 39/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.2512 - accuracy: 0.8945 - val_loss: 0.2188 - val_accuracy: 0.9126\n","Epoch 40/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2463 - accuracy: 0.8971 - val_loss: 0.2144 - val_accuracy: 0.9132\n","Epoch 41/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2506 - accuracy: 0.8934 - val_loss: 0.2397 - val_accuracy: 0.9049\n","Epoch 42/150\n","158/158 [==============================] - 36s 230ms/step - loss: 0.2398 - accuracy: 0.9001 - val_loss: 0.2271 - val_accuracy: 0.9025\n","Epoch 43/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.2453 - accuracy: 0.8997 - val_loss: 0.2159 - val_accuracy: 0.9090\n","Epoch 44/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2395 - accuracy: 0.9013 - val_loss: 0.2624 - val_accuracy: 0.8978\n","Epoch 45/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2374 - accuracy: 0.9080 - val_loss: 0.2278 - val_accuracy: 0.9149\n","Epoch 46/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.2388 - accuracy: 0.9043 - val_loss: 0.2345 - val_accuracy: 0.9055\n","Epoch 47/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.2313 - accuracy: 0.9031 - val_loss: 0.2431 - val_accuracy: 0.9090\n","Epoch 48/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.2303 - accuracy: 0.9035 - val_loss: 0.2351 - val_accuracy: 0.9061\n","Epoch 49/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2410 - accuracy: 0.9039 - val_loss: 0.2123 - val_accuracy: 0.9096\n","Epoch 50/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.2284 - accuracy: 0.9088 - val_loss: 0.2130 - val_accuracy: 0.9114\n","Epoch 51/150\n","158/158 [==============================] - 40s 256ms/step - loss: 0.2272 - accuracy: 0.9043 - val_loss: 0.2515 - val_accuracy: 0.9008\n","Epoch 52/150\n","158/158 [==============================] - 35s 225ms/step - loss: 0.2261 - accuracy: 0.9104 - val_loss: 0.2314 - val_accuracy: 0.9055\n","Epoch 53/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.2134 - accuracy: 0.9060 - val_loss: 0.2574 - val_accuracy: 0.9008\n","Epoch 54/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.2192 - accuracy: 0.9088 - val_loss: 0.2105 - val_accuracy: 0.9144\n","Epoch 55/150\n","158/158 [==============================] - 35s 225ms/step - loss: 0.2137 - accuracy: 0.9162 - val_loss: 0.2200 - val_accuracy: 0.9108\n","Epoch 56/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.2232 - accuracy: 0.9005 - val_loss: 0.2322 - val_accuracy: 0.9120\n","Epoch 57/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2307 - accuracy: 0.9029 - val_loss: 0.2036 - val_accuracy: 0.9167\n","Epoch 58/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.2067 - accuracy: 0.9148 - val_loss: 0.2099 - val_accuracy: 0.9191\n","Epoch 59/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2002 - accuracy: 0.9201 - val_loss: 0.2112 - val_accuracy: 0.9096\n","Epoch 60/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.2081 - accuracy: 0.9203 - val_loss: 0.2551 - val_accuracy: 0.9008\n","Epoch 61/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.2062 - accuracy: 0.9146 - val_loss: 0.1970 - val_accuracy: 0.9167\n","Epoch 62/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.2270 - accuracy: 0.9098 - val_loss: 0.2246 - val_accuracy: 0.9090\n","Epoch 63/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.2050 - accuracy: 0.9162 - val_loss: 0.2180 - val_accuracy: 0.9167\n","Epoch 64/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1997 - accuracy: 0.9171 - val_loss: 0.2010 - val_accuracy: 0.9155\n","Epoch 65/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1959 - accuracy: 0.9197 - val_loss: 0.2149 - val_accuracy: 0.9138\n","Epoch 66/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.1874 - accuracy: 0.9213 - val_loss: 0.2077 - val_accuracy: 0.9250\n","Epoch 67/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.2059 - accuracy: 0.9179 - val_loss: 0.2066 - val_accuracy: 0.9102\n","Epoch 68/150\n","158/158 [==============================] - 40s 250ms/step - loss: 0.1770 - accuracy: 0.9296 - val_loss: 0.2059 - val_accuracy: 0.9185\n","Epoch 69/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1967 - accuracy: 0.9179 - val_loss: 0.2088 - val_accuracy: 0.9203\n","Epoch 70/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1935 - accuracy: 0.9233 - val_loss: 0.1960 - val_accuracy: 0.9203\n","Epoch 71/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1944 - accuracy: 0.9223 - val_loss: 0.2132 - val_accuracy: 0.9108\n","Epoch 72/150\n","158/158 [==============================] - 36s 228ms/step - loss: 0.1792 - accuracy: 0.9249 - val_loss: 0.2053 - val_accuracy: 0.9262\n","Epoch 73/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1934 - accuracy: 0.9245 - val_loss: 0.2231 - val_accuracy: 0.9185\n","Epoch 74/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1828 - accuracy: 0.9278 - val_loss: 0.2145 - val_accuracy: 0.9108\n","Epoch 75/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1802 - accuracy: 0.9271 - val_loss: 0.2046 - val_accuracy: 0.9262\n","Epoch 76/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.1763 - accuracy: 0.9282 - val_loss: 0.2119 - val_accuracy: 0.9232\n","Epoch 77/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.1842 - accuracy: 0.9263 - val_loss: 0.2209 - val_accuracy: 0.9132\n","Epoch 78/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.1926 - accuracy: 0.9189 - val_loss: 0.2216 - val_accuracy: 0.9132\n","Epoch 79/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.1862 - accuracy: 0.9223 - val_loss: 0.2361 - val_accuracy: 0.9161\n","Epoch 80/150\n","158/158 [==============================] - 35s 223ms/step - loss: 0.1917 - accuracy: 0.9235 - val_loss: 0.1915 - val_accuracy: 0.9256\n","Epoch 81/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1774 - accuracy: 0.9288 - val_loss: 0.2153 - val_accuracy: 0.9173\n","Epoch 82/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1737 - accuracy: 0.9314 - val_loss: 0.2095 - val_accuracy: 0.9232\n","Epoch 83/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1664 - accuracy: 0.9304 - val_loss: 0.2117 - val_accuracy: 0.9220\n","Epoch 84/150\n","158/158 [==============================] - 35s 225ms/step - loss: 0.1724 - accuracy: 0.9292 - val_loss: 0.2094 - val_accuracy: 0.9238\n","Epoch 85/150\n","158/158 [==============================] - 39s 244ms/step - loss: 0.1727 - accuracy: 0.9348 - val_loss: 0.2118 - val_accuracy: 0.9167\n","Epoch 86/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.1852 - accuracy: 0.9237 - val_loss: 0.1939 - val_accuracy: 0.9273\n","Epoch 87/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.1706 - accuracy: 0.9277 - val_loss: 0.2193 - val_accuracy: 0.9167\n","Epoch 88/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.1691 - accuracy: 0.9348 - val_loss: 0.2265 - val_accuracy: 0.9126\n","Epoch 89/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.1685 - accuracy: 0.9284 - val_loss: 0.2170 - val_accuracy: 0.9232\n","Epoch 90/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.1719 - accuracy: 0.9320 - val_loss: 0.2098 - val_accuracy: 0.9232\n","Epoch 91/150\n","158/158 [==============================] - 36s 228ms/step - loss: 0.1612 - accuracy: 0.9397 - val_loss: 0.2216 - val_accuracy: 0.9244\n","Epoch 92/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1572 - accuracy: 0.9372 - val_loss: 0.2282 - val_accuracy: 0.9161\n","Epoch 93/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.1592 - accuracy: 0.9378 - val_loss: 0.2183 - val_accuracy: 0.9173\n","Epoch 94/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1624 - accuracy: 0.9334 - val_loss: 0.2413 - val_accuracy: 0.9084\n","Epoch 95/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1572 - accuracy: 0.9374 - val_loss: 0.2114 - val_accuracy: 0.9232\n","Epoch 96/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1562 - accuracy: 0.9358 - val_loss: 0.2195 - val_accuracy: 0.9173\n","Epoch 97/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1630 - accuracy: 0.9364 - val_loss: 0.2225 - val_accuracy: 0.9220\n","Epoch 98/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1695 - accuracy: 0.9324 - val_loss: 0.2145 - val_accuracy: 0.9185\n","Epoch 99/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1673 - accuracy: 0.9304 - val_loss: 0.2126 - val_accuracy: 0.9250\n","Epoch 100/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1590 - accuracy: 0.9382 - val_loss: 0.2042 - val_accuracy: 0.9203\n","Epoch 101/150\n","158/158 [==============================] - 36s 228ms/step - loss: 0.1448 - accuracy: 0.9415 - val_loss: 0.2050 - val_accuracy: 0.9167\n","Epoch 102/150\n","158/158 [==============================] - 39s 246ms/step - loss: 0.1573 - accuracy: 0.9358 - val_loss: 0.2178 - val_accuracy: 0.9214\n","Epoch 103/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.1601 - accuracy: 0.9344 - val_loss: 0.2451 - val_accuracy: 0.9155\n","Epoch 104/150\n","158/158 [==============================] - 35s 224ms/step - loss: 0.1585 - accuracy: 0.9360 - val_loss: 0.2380 - val_accuracy: 0.9209\n","Epoch 105/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1475 - accuracy: 0.9423 - val_loss: 0.2915 - val_accuracy: 0.9019\n","Epoch 106/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1521 - accuracy: 0.9388 - val_loss: 0.2201 - val_accuracy: 0.9161\n","Epoch 107/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1494 - accuracy: 0.9411 - val_loss: 0.1919 - val_accuracy: 0.9250\n","Epoch 108/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1579 - accuracy: 0.9354 - val_loss: 0.2174 - val_accuracy: 0.9226\n","Epoch 109/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1431 - accuracy: 0.9437 - val_loss: 0.1941 - val_accuracy: 0.9244\n","Epoch 110/150\n","158/158 [==============================] - 36s 229ms/step - loss: 0.1596 - accuracy: 0.9391 - val_loss: 0.1975 - val_accuracy: 0.9244\n","Epoch 111/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.1433 - accuracy: 0.9431 - val_loss: 0.2239 - val_accuracy: 0.9232\n","Epoch 112/150\n","158/158 [==============================] - 36s 228ms/step - loss: 0.1421 - accuracy: 0.9435 - val_loss: 0.2184 - val_accuracy: 0.9220\n","Epoch 113/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1375 - accuracy: 0.9451 - val_loss: 0.2125 - val_accuracy: 0.9214\n","Epoch 114/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.1386 - accuracy: 0.9433 - val_loss: 0.2229 - val_accuracy: 0.9197\n","Epoch 115/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1389 - accuracy: 0.9469 - val_loss: 0.2120 - val_accuracy: 0.9185\n","Epoch 116/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1323 - accuracy: 0.9469 - val_loss: 0.2149 - val_accuracy: 0.9256\n","Epoch 117/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1377 - accuracy: 0.9457 - val_loss: 0.2248 - val_accuracy: 0.9203\n","Epoch 118/150\n","158/158 [==============================] - 37s 235ms/step - loss: 0.1381 - accuracy: 0.9447 - val_loss: 0.2821 - val_accuracy: 0.9126\n","Epoch 119/150\n","158/158 [==============================] - 39s 249ms/step - loss: 0.1416 - accuracy: 0.9455 - val_loss: 0.2264 - val_accuracy: 0.9214\n","Epoch 120/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1368 - accuracy: 0.9500 - val_loss: 0.2380 - val_accuracy: 0.9203\n","Epoch 121/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1408 - accuracy: 0.9439 - val_loss: 0.2149 - val_accuracy: 0.9220\n","Epoch 122/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1372 - accuracy: 0.9469 - val_loss: 0.2678 - val_accuracy: 0.9149\n","Epoch 123/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1333 - accuracy: 0.9483 - val_loss: 0.2149 - val_accuracy: 0.9273\n","Epoch 124/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1296 - accuracy: 0.9491 - val_loss: 0.2231 - val_accuracy: 0.9273\n","Epoch 125/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1466 - accuracy: 0.9452 - val_loss: 0.2105 - val_accuracy: 0.9279\n","Epoch 126/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1386 - accuracy: 0.9445 - val_loss: 0.2095 - val_accuracy: 0.9238\n","Epoch 127/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.1351 - accuracy: 0.9500 - val_loss: 0.2244 - val_accuracy: 0.9303\n","Epoch 128/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.1329 - accuracy: 0.9475 - val_loss: 0.2681 - val_accuracy: 0.9185\n","Epoch 129/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1328 - accuracy: 0.9495 - val_loss: 0.2274 - val_accuracy: 0.9268\n","Epoch 130/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1252 - accuracy: 0.9532 - val_loss: 0.2267 - val_accuracy: 0.9185\n","Epoch 131/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1253 - accuracy: 0.9520 - val_loss: 0.2410 - val_accuracy: 0.9250\n","Epoch 132/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1325 - accuracy: 0.9477 - val_loss: 0.2173 - val_accuracy: 0.9291\n","Epoch 133/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1202 - accuracy: 0.9542 - val_loss: 0.2135 - val_accuracy: 0.9214\n","Epoch 134/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1286 - accuracy: 0.9485 - val_loss: 0.2451 - val_accuracy: 0.9232\n","Epoch 135/150\n","158/158 [==============================] - 41s 257ms/step - loss: 0.1282 - accuracy: 0.9510 - val_loss: 0.2213 - val_accuracy: 0.9273\n","Epoch 136/150\n","158/158 [==============================] - 36s 228ms/step - loss: 0.1306 - accuracy: 0.9499 - val_loss: 0.2154 - val_accuracy: 0.9350\n","Epoch 137/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1362 - accuracy: 0.9459 - val_loss: 0.2195 - val_accuracy: 0.9214\n","Epoch 138/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1296 - accuracy: 0.9491 - val_loss: 0.2110 - val_accuracy: 0.9303\n","Epoch 139/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1331 - accuracy: 0.9481 - val_loss: 0.2020 - val_accuracy: 0.9279\n","Epoch 140/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1149 - accuracy: 0.9582 - val_loss: 0.2313 - val_accuracy: 0.9214\n","Epoch 141/150\n","158/158 [==============================] - 36s 225ms/step - loss: 0.1247 - accuracy: 0.9493 - val_loss: 0.2220 - val_accuracy: 0.9250\n","Epoch 142/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1212 - accuracy: 0.9520 - val_loss: 0.2220 - val_accuracy: 0.9315\n","Epoch 143/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1199 - accuracy: 0.9538 - val_loss: 0.2105 - val_accuracy: 0.9333\n","Epoch 144/150\n","158/158 [==============================] - 36s 229ms/step - loss: 0.1233 - accuracy: 0.9534 - val_loss: 0.2095 - val_accuracy: 0.9315\n","Epoch 145/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.1141 - accuracy: 0.9554 - val_loss: 0.2404 - val_accuracy: 0.9167\n","Epoch 146/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1216 - accuracy: 0.9538 - val_loss: 0.2550 - val_accuracy: 0.9203\n","Epoch 147/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1225 - accuracy: 0.9518 - val_loss: 0.2337 - val_accuracy: 0.9191\n","Epoch 148/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1182 - accuracy: 0.9518 - val_loss: 0.2225 - val_accuracy: 0.9191\n","Epoch 149/150\n","158/158 [==============================] - 36s 227ms/step - loss: 0.1235 - accuracy: 0.9522 - val_loss: 0.2339 - val_accuracy: 0.9209\n","Epoch 150/150\n","158/158 [==============================] - 36s 226ms/step - loss: 0.1181 - accuracy: 0.9526 - val_loss: 0.2067 - val_accuracy: 0.9315\n","[INFORMATION] Second CNN Model sucessfully trained\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BJtfwrcsH8il","colab_type":"text"},"source":["# **9. Second Model Evaluating**"]},{"cell_type":"code","metadata":{"id":"3SKZncFXIBXR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1600550093194,"user_tz":180,"elapsed":5316,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}},"outputId":"9c7b3a00-5867-491d-f2d7-86fc4c01e15e"},"source":["# evaluate the network\n","print('[INFORMATION] Starting Neural Network Evaluation...')\n","predictions = model.predict(testX, batch_size = 32)\n","print(classification_report(testY.argmax(axis=1),\n","                            predictions.argmax(axis = 1),\n","                            target_names = lb.classes_))\n","\n","# plot the training loss and accuracy curves\n","N = np.arange(0, EPOCHS)\n","plt.style.use('ggplot')\n","plt.figure(figsize=(10,10))\n","plt.plot(N, H.history['loss'], label = 'train_loss')\n","plt.plot(N, H.history['val_loss'], label = 'val_loss')\n","plt.plot(N, H.history['accuracy'], label = 'train_acc')\n","plt.plot(N, H.history['val_accuracy'], label = 'val_acc')\n","plt.title('Training Loss and Accuracy (Simple CNN)')\n","plt.xlabel('Epoch #')\n","plt.ylabel('Loss / Accuracy')\n","plt.legend()\n","plt.show()\n","plt.savefig(SAVE_PATH_CNN + '/learning_curve.png')\n","\n","# save the model and label binarizer to disk\n","print('[INFORMATION] Serializing Network and Label Binarizer...')\n","LABEL_BIN = SAVE_PATH_CNN + '/binarizer.txt'\n","model.save(SAVE_PATH_CNN)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[INFORMATION] Starting Neural Network Evaluation...\n","              precision    recall  f1-score   support\n","\n","         Man       0.93      0.93      0.93       849\n","       Woman       0.93      0.93      0.93       844\n","\n","    accuracy                           0.93      1693\n","   macro avg       0.93      0.93      0.93      1693\n","weighted avg       0.93      0.93      0.93      1693\n","\n","[INFORMATION] Serializing Network and Label Binarizer...\n","INFO:tensorflow:Assets written to: drive/My Drive/Facial Classification - Gender/SimpleCNN_results/assets\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5f6k6f_3QDAd","colab_type":"text"},"source":["# **10. First Model Testing**"]},{"cell_type":"code","metadata":{"id":"y_6PY7m6ZPKN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600550105612,"user_tz":180,"elapsed":4468,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}},"outputId":"b322fca9-9d34-4bc1-f3ad-5e51954558d1"},"source":["# load the desired model and label binarizer\n","print('[INFORMATION] Loading Neural Network Model and Label Binarizer')\n","model = load_model(SAVE_PATH_VGG)\n","\n","# load images to predict\n","PREDICT_PATH = 'drive/My Drive/Facial Classification - Gender/dataset_test'\n","imagePaths = sorted(list(paths.list_images(PREDICT_PATH)))\n","\n","plt.figure(figsize=(10,10))\n","plt.subplots_adjust(wspace = 0.2, hspace = 0.01)\n","k = 1\n","for imagePath in imagePaths:\n","  # load the image, resize it to 64 x 64 pixels, and store it in the data list\n","  image = cv2.imread(imagePath)\n","  output = image.copy()\n","  image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n","\n","  # add the batch dimension\n","  image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","\n","  # make a prediction on the image\n","  preds = model.predict(image)\n","\n","  # find the class label index with the largest corresponding probability\n","  i = preds.argmax(axis = 1)[0]\n","  if i == 0:\n","    label = 'Man'\n","  else:\n","    label = 'Woman'\n","\n","  # draw the class label + probability on the output image\n","  text = '{}: {:.2f} %'.format(label, preds[0][i]*100)\n","\n","  # show the output imges\n","  plt.subplot(2, 5, k)\n","  plt.imshow(output)\n","  plt.title(text, fontsize = 10)\n","  plt.grid(b=None)\n","  plt.axis('off')\n","\n","  k += 1\n","\n","plt.savefig(SAVE_PATH_VGG + '/predictions.png')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[INFORMATION] Loading Neural Network Model and Label Binarizer\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v3o-doPuQOIZ","colab_type":"text"},"source":["# **11. Second Model Testing**"]},{"cell_type":"code","metadata":{"id":"Bh-HYujyQfK5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600550118895,"user_tz":180,"elapsed":3482,"user":{"displayName":"Z Data Analytics","photoUrl":"","userId":"16949941712119068760"}},"outputId":"01f7c7c1-9ffc-4cc8-efdc-86b38c7d49f2"},"source":["# load the desired model and label binarizer\n","print('[INFORMATION] Loading Neural Network Model and Label Binarizer')\n","model = load_model(SAVE_PATH_CNN)\n","\n","# load images to predict\n","PREDICT_PATH = 'drive/My Drive/Facial Classification - Gender/dataset_test'\n","imagePaths = sorted(list(paths.list_images(PREDICT_PATH)))\n","\n","plt.figure(figsize=(10,10))\n","plt.subplots_adjust(wspace = 0.2, hspace = 0.01)\n","k = 1\n","for imagePath in imagePaths:\n","  # load the image, resize it to 64 x 64 pixels, and store it in the data list\n","  image = cv2.imread(imagePath)\n","  output = image.copy()\n","  image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n","\n","  # add the batch dimension\n","  image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","\n","  # make a prediction on the image\n","  preds = model.predict(image)\n","\n","  # find the class label index with the largest corresponding probability\n","  i = preds.argmax(axis = 1)[0]\n","  if i == 0:\n","    label = 'Man'\n","  else:\n","    label = 'Woman'\n","\n","  # draw the class label + probability on the output image\n","  text = '{}: {:.2f} %'.format(label, preds[0][i]*100)\n","\n","  # show the output imges\n","  plt.subplot(2, 5, k)\n","  plt.imshow(output)\n","  plt.title(text, fontsize = 10)\n","  plt.grid(b=None)\n","  plt.axis('off')\n","\n","  k += 1\n","\n","plt.savefig(SAVE_PATH_CNN + '/predictions.png')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[INFORMATION] Loading Neural Network Model and Label Binarizer\n"],"name":"stdout"}]}]}